{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21a69ef-6f78-44f6-a7d0-bb3cadd8789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName(\"Spark Demo\")\\\n",
    "        .getOrCreate()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817c5036-faf0-4251-9e45-66daf8147541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "+---+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "df =spark.range(10)\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23da09d4-e50c-4762-91ec-595b69e2be93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df930e9-c433-4b7c-838b-7a36f786bb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, id: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff13b06a-0f77-4825-b391-ddd3934907a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c127648-be85-4fe9-a3b0-9fdf2076b044",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2016332507.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcolumns = [id: int, name: string, salary :float]\u001b[39m\n                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe using list of tuples\n",
    "data = [\n",
    "    (1, \"Ravi\", 50000),\n",
    "    (2, \"Priya\", 60000),\n",
    "    (3, \"John\", 45000)\n",
    "]\n",
    "\n",
    "columns = [id: int, name: string, salary :float]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd72892a-2419-496a-9d38-d951d5e73d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id int', 'bigint'), ('name string', 'string'), ('salary float', 'bigint')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214480c-208f-47f9-afe6-f7f0c6f7d475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb49afa5-4055-40bc-abf0-ef2b86a88628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| id|  name|age|\n",
      "+---+------+---+\n",
      "|  1| Kumar| 28|\n",
      "|  2| Anita| 32|\n",
      "|  3|George| 40|\n",
      "+---+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating data frame wit schema\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (1, \"Kumar\", 28),\n",
    "    (2, \"Anita\", 32),\n",
    "    (3, \"George\", 40)\n",
    "]\n",
    "\n",
    "df2 = spark.createDataFrame(data, schema)\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "434f83b9-d0d3-46bf-9776-1dfe13f1f0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'), ('name', 'string'), ('age', 'int')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3f0ab0-9adc-4898-966c-66e38ee4c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1| Ravi| 50000|\n",
      "|  2|Priya| 60000|\n",
      "|  3| John| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe using dictionary\n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Ravi\", \"salary\": 50000},\n",
    "    {\"id\": 2, \"name\": \"Priya\", \"salary\": 60000},\n",
    "    {\"id\": 3, \"name\": \"John\", \"salary\": 45000}\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9074499e-e5cd-47e8-8f96-5f95be5fcfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('c:/data/Orders', \"order_id int,order_date timestamp,customer_id int,order_status string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3364649c-f0b7-4c27-9886-f689f5d89133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "627a6696-f2e0-44e3-b9b2-3af5995f20da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|         status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('c:/data/Orders1', header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5f9d65-7236-4450-a226-aa282d171431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, order_id: string, customer_id: string, status: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d253e0-f73b-4d19-ae00-6d7234094e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abcd785e-56d8-46d5-b340-b0628a6bfebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"order_date\", TimestampType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"order_status\", StringType(), True),\n",
    "        \n",
    "])\n",
    "df = spark.read.csv('c:/data/Orders',schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0634b20-f418-4c33-b682-8313e2453c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92eb956e-22a1-48ac-8f67-f8a5e251c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|order_id|         order_date|\n",
      "+--------+-------------------+\n",
      "|       1|2013-07-25 00:00:00|\n",
      "|       2|2013-07-25 00:00:00|\n",
      "|       3|2013-07-25 00:00:00|\n",
      "|       4|2013-07-25 00:00:00|\n",
      "|       5|2013-07-25 00:00:00|\n",
      "|       6|2013-07-25 00:00:00|\n",
      "|       7|2013-07-25 00:00:00|\n",
      "|       8|2013-07-25 00:00:00|\n",
      "|       9|2013-07-25 00:00:00|\n",
      "|      10|2013-07-25 00:00:00|\n",
      "|      11|2013-07-25 00:00:00|\n",
      "|      12|2013-07-25 00:00:00|\n",
      "|      13|2013-07-25 00:00:00|\n",
      "|      14|2013-07-25 00:00:00|\n",
      "|      15|2013-07-25 00:00:00|\n",
      "|      16|2013-07-25 00:00:00|\n",
      "|      17|2013-07-25 00:00:00|\n",
      "|      18|2013-07-25 00:00:00|\n",
      "|      19|2013-07-25 00:00:00|\n",
      "|      20|2013-07-25 00:00:00|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(\"order_id\",\"order_date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2092bce-0309-42c5-b0ca-67284d02d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------------+\n",
      "|order_id|         order_date|   order_status|\n",
      "+--------+-------------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|     PROCESSING|\n",
      "+--------+-------------------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select(df.order_id,df.order_date,df.order_status).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba673abe-2b7d-4715-893f-a86b2d49ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------------+\n",
      "| id|order_id|               date|\n",
      "+---+--------+-------------------+\n",
      "|  1|     100|2013-07-25 00:00:00|\n",
      "|  2|     200|2013-07-25 00:00:00|\n",
      "|  3|     300|2013-07-25 00:00:00|\n",
      "|  4|     400|2013-07-25 00:00:00|\n",
      "|  5|     500|2013-07-25 00:00:00|\n",
      "|  6|     600|2013-07-25 00:00:00|\n",
      "|  7|     700|2013-07-25 00:00:00|\n",
      "|  8|     800|2013-07-25 00:00:00|\n",
      "|  9|     900|2013-07-25 00:00:00|\n",
      "| 10|    1000|2013-07-25 00:00:00|\n",
      "| 11|    1100|2013-07-25 00:00:00|\n",
      "| 12|    1200|2013-07-25 00:00:00|\n",
      "| 13|    1300|2013-07-25 00:00:00|\n",
      "| 14|    1400|2013-07-25 00:00:00|\n",
      "| 15|    1500|2013-07-25 00:00:00|\n",
      "| 16|    1600|2013-07-25 00:00:00|\n",
      "| 17|    1700|2013-07-25 00:00:00|\n",
      "| 18|    1800|2013-07-25 00:00:00|\n",
      "| 19|    1900|2013-07-25 00:00:00|\n",
      "| 20|    2000|2013-07-25 00:00:00|\n",
      "+---+--------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"order_id\").alias(\"id\"),\n",
    "          (col(\"order_id\") * 100).alias(\"order_id\"),\n",
    "          col(\"order_date\").alias(\"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf5bc87e-6c96-496a-9f2f-7d600ff89144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+\n",
      "|order_id|         order_date|customer_id|\n",
      "+--------+-------------------+-----------+\n",
      "|       1|2013-07-25 00:00:00|      11599|\n",
      "|       2|2013-07-25 00:00:00|        256|\n",
      "|       3|2013-07-25 00:00:00|      12111|\n",
      "|       4|2013-07-25 00:00:00|       8827|\n",
      "|       5|2013-07-25 00:00:00|      11318|\n",
      "|       6|2013-07-25 00:00:00|       7130|\n",
      "|       7|2013-07-25 00:00:00|       4530|\n",
      "|       8|2013-07-25 00:00:00|       2911|\n",
      "|       9|2013-07-25 00:00:00|       5657|\n",
      "|      10|2013-07-25 00:00:00|       5648|\n",
      "|      11|2013-07-25 00:00:00|        918|\n",
      "|      12|2013-07-25 00:00:00|       1837|\n",
      "|      13|2013-07-25 00:00:00|       9149|\n",
      "|      14|2013-07-25 00:00:00|       9842|\n",
      "|      15|2013-07-25 00:00:00|       2568|\n",
      "|      16|2013-07-25 00:00:00|       7276|\n",
      "|      17|2013-07-25 00:00:00|       2667|\n",
      "|      18|2013-07-25 00:00:00|       1205|\n",
      "|      19|2013-07-25 00:00:00|       9488|\n",
      "|      20|2013-07-25 00:00:00|       9198|\n",
      "+--------+-------------------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.select( [x for x in df.columns if x !='order_status']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa21b838-3a9f-49c1-a9be-f006ab2cd143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+---------------+\n",
      "|order_id|order_date         |order_status   |\n",
      "+--------+-------------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|6       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|7       |2013-07-25 00:00:00|COMPLETE       |\n",
      "|8       |2013-07-25 00:00:00|PROCESSING     |\n",
      "|9       |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|11      |2013-07-25 00:00:00|PAYMENT_REVIEW |\n",
      "|12      |2013-07-25 00:00:00|CLOSED         |\n",
      "|13      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|14      |2013-07-25 00:00:00|PROCESSING     |\n",
      "|15      |2013-07-25 00:00:00|COMPLETE       |\n",
      "|16      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|17      |2013-07-25 00:00:00|COMPLETE       |\n",
      "|18      |2013-07-25 00:00:00|CLOSED         |\n",
      "|19      |2013-07-25 00:00:00|PENDING_PAYMENT|\n",
      "|20      |2013-07-25 00:00:00|PROCESSING     |\n",
      "+--------+-------------------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"order_id\",\"order_date\",\"upper(order_status) as order_status\" ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1168a142-0c2c-46b9-b20a-2b2eed00ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+------------------+\n",
      "|order_id|         order_date|customer_id|   order_status|order_status_upper|\n",
      "+--------+-------------------+-----------+---------------+------------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|            CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|          COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|            CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|          COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|          COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|          COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|        PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|    PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|            CLOSED|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|        PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|          COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|          COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|            CLOSED|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|   PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|        PROCESSING|\n",
      "+--------+-------------------+-----------+---------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"order_status_upper\", upper(col( \"order_status\"))).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d746848e-47b4-4019-ab11-3601f2dc3efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+--------------+\n",
      "|order_id|         order_date|customer_id|   order_status|order_id * 100|\n",
      "+--------+-------------------+-----------+---------------+--------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|           100|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|           200|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|           300|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|           400|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|           500|\n",
      "|       6|2013-07-25 00:00:00|       7130|       COMPLETE|           600|\n",
      "|       7|2013-07-25 00:00:00|       4530|       COMPLETE|           700|\n",
      "|       8|2013-07-25 00:00:00|       2911|     PROCESSING|           800|\n",
      "|       9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|           900|\n",
      "|      10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|          1000|\n",
      "|      11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|          1100|\n",
      "|      12|2013-07-25 00:00:00|       1837|         CLOSED|          1200|\n",
      "|      13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|          1300|\n",
      "|      14|2013-07-25 00:00:00|       9842|     PROCESSING|          1400|\n",
      "|      15|2013-07-25 00:00:00|       2568|       COMPLETE|          1500|\n",
      "|      16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|          1600|\n",
      "|      17|2013-07-25 00:00:00|       2667|       COMPLETE|          1700|\n",
      "|      18|2013-07-25 00:00:00|       1205|         CLOSED|          1800|\n",
      "|      19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|          1900|\n",
      "|      20|2013-07-25 00:00:00|       9198|     PROCESSING|          2000|\n",
      "+--------+-------------------+-----------+---------------+--------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"order_id * 100\", col(\"order_id\") * 100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06813605-0ff2-47d9-9765-ff49b72c6f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+---------------+\n",
      "|orderId|         order_date|customer_id|   order_status|\n",
      "+-------+-------------------+-----------+---------------+\n",
      "|      1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|      2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|      4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|      5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|      6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "|      7|2013-07-25 00:00:00|       4530|       COMPLETE|\n",
      "|      8|2013-07-25 00:00:00|       2911|     PROCESSING|\n",
      "|      9|2013-07-25 00:00:00|       5657|PENDING_PAYMENT|\n",
      "|     10|2013-07-25 00:00:00|       5648|PENDING_PAYMENT|\n",
      "|     11|2013-07-25 00:00:00|        918| PAYMENT_REVIEW|\n",
      "|     12|2013-07-25 00:00:00|       1837|         CLOSED|\n",
      "|     13|2013-07-25 00:00:00|       9149|PENDING_PAYMENT|\n",
      "|     14|2013-07-25 00:00:00|       9842|     PROCESSING|\n",
      "|     15|2013-07-25 00:00:00|       2568|       COMPLETE|\n",
      "|     16|2013-07-25 00:00:00|       7276|PENDING_PAYMENT|\n",
      "|     17|2013-07-25 00:00:00|       2667|       COMPLETE|\n",
      "|     18|2013-07-25 00:00:00|       1205|         CLOSED|\n",
      "|     19|2013-07-25 00:00:00|       9488|PENDING_PAYMENT|\n",
      "|     20|2013-07-25 00:00:00|       9198|     PROCESSING|\n",
      "+-------+-------------------+-----------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"order_id\", \"orderId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a581d3d9-14dd-4932-98aa-c005884fbb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Ravi\", \"salary\": 50000, \"deptno\":10},\n",
    "    {\"id\": 2, \"name\": \"Priya\", \"salary\": 60000, \"deptno\":10},\n",
    "    {\"id\": 3, \"name\": \"John\", \"salary\": 45000, \"deptno\":20},\n",
    "    {\"id\": 4, \"name\": \"Rashmi\", \"salary\": 80000, \"deptno\":20},\n",
    "    {\"id\": 5, \"name\": \"Prem\", \"salary\": 25000, \"deptno\":30},\n",
    "    {\"id\": 6, \"name\": \"Raheem\", \"salary\": 50000, \"deptno\":30},\n",
    "    {\"id\": 7, \"name\": \"Sunil\", \"salary\": 30000, \"deptno\":10},\n",
    "    {\"id\": 8, \"name\": \"John\", \"salary\": 35000, \"deptno\":10},\n",
    "    {\"id\": 9, \"name\": \"Susil\", \"salary\": 45000, \"deptno\":20},\n",
    "    {\"id\": 10, \"name\": \"Jothi\", \"salary\": 75000, \"deptno\":10}    \n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c157e0c0-8ac6-47c3-a04e-5db95551faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+------+\n",
      "|deptno| id|  name|salary|Status|\n",
      "+------+---+------+------+------+\n",
      "|    10|  1|  Ravi| 50000|   LOW|\n",
      "|    10|  2| Priya| 60000|  HIGH|\n",
      "|    20|  3|  John| 45000|   LOW|\n",
      "|    20|  4|Rashmi| 80000|  HIGH|\n",
      "|    30|  5|  Prem| 25000|   LOW|\n",
      "|    30|  6|Raheem| 50000|   LOW|\n",
      "|    10|  7| Sunil| 30000|   LOW|\n",
      "|    10|  8|  John| 35000|   LOW|\n",
      "|    20|  9| Susil| 45000|   LOW|\n",
      "|    10| 10| Jothi| 75000|  HIGH|\n",
      "+------+---+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Status\",\n",
    "              when(col(\"salary\") > 50000, \"HIGH\").otherwise(\"LOW\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88a5dc43-30ff-4e41-a842-2f370952a246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+----------+------------------+-----------+\n",
      "|deptno| id|  name|salary|name_upper|    salary_plus_10|salary_flag|\n",
      "+------+---+------+------+----------+------------------+-----------+\n",
      "|    10|  1|  Ravi| 50000|      RAVI| 55000.00000000001|        LOW|\n",
      "|    10|  2| Priya| 60000|     PRIYA|           66000.0|       HIGH|\n",
      "|    20|  3|  John| 45000|      JOHN| 49500.00000000001|        LOW|\n",
      "|    20|  4|Rashmi| 80000|    RASHMI|           88000.0|       HIGH|\n",
      "|    30|  5|  Prem| 25000|      PREM|27500.000000000004|        LOW|\n",
      "|    30|  6|Raheem| 50000|    RAHEEM| 55000.00000000001|        LOW|\n",
      "|    10|  7| Sunil| 30000|     SUNIL|           33000.0|        LOW|\n",
      "|    10|  8|  John| 35000|      JOHN|           38500.0|        LOW|\n",
      "|    20|  9| Susil| 45000|     SUSIL| 49500.00000000001|        LOW|\n",
      "|    10| 10| Jothi| 75000|     JOTHI|           82500.0|       HIGH|\n",
      "+------+---+------+------+----------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumns({\n",
    "    \"name_upper\": upper(col(\"name\")),\n",
    "    \"salary_plus_10\": col(\"salary\") * 1.10,\n",
    "    \"salary_flag\": when(col(\"salary\") > 50000, \"HIGH\").otherwise(\"LOW\")\n",
    "})\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2612aa4a-d02f-4c6e-82e8-59d1b5b82c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"order_status\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68b3cb69-8af4-4f47-b185-542ef3f35373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "|  3|Shiva|        HR|\n",
      "|  4|Shiva| Marketing|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Shiva\", \"HR\"),\n",
    "    (2, \"Reddy\", \"Finance\"),\n",
    "    (3, \"Shiva\", \"HR\"),      # duplicate row\n",
    "    (4, \"Shiva\", \"Marketing\")\n",
    "]\n",
    "\n",
    "df1 = spark.createDataFrame(data, [\"id\", \"name\", \"department\"])\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bcb5d71c-fb58-4400-ab5e-2f72ef80144e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "|  3|Shiva|        HR|\n",
      "|  4|Shiva| Marketing|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd8448a2-3275-4d72-9fc7-50e025ef54da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "| id| name|department|\n",
      "+---+-----+----------+\n",
      "|  1|Shiva|        HR|\n",
      "|  2|Reddy|   Finance|\n",
      "|  4|Shiva| Marketing|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop_duplicates(subset=[\"department\",\"name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea374743-c39a-4485-8b55-d6f656112f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|  id| name|salary|\n",
      "+----+-----+------+\n",
      "|   1|Shiva| 60000|\n",
      "|   2| NULL| 45000|\n",
      "|   3|Reddy|  NULL|\n",
      "|NULL|Kumar| 30000|\n",
      "|   5| NULL|  NULL|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Shiva\",    60000),\n",
    "    (2, None,       45000),\n",
    "    (3, \"Reddy\",    None),\n",
    "    (None, \"Kumar\", 30000),\n",
    "    (5, None,       None)\n",
    "]\n",
    "\n",
    "df2 = spark.createDataFrame(data, [\"id\", \"name\", \"salary\"])\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24adde91-0de7-49a6-962e-1d2516367f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|  id| name|salary|\n",
      "+----+-----+------+\n",
      "|   1|Shiva| 60000|\n",
      "|   2| NULL| 45000|\n",
      "|   3|Reddy|  NULL|\n",
      "|NULL|Kumar| 30000|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.dropna(thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9fbb08ce-d0fd-4384-b83d-425d18622e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|  id| name|salary|\n",
      "+----+-----+------+\n",
      "|   1|Shiva| 60000|\n",
      "|   2| NULL| 45000|\n",
      "|NULL|Kumar| 30000|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.dropna(subset=[\"salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b29c6d0e-a157-4d87-98c2-790a4beba902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Shiva| 60000|\n",
      "|  2| NULL| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.dropna(subset=[\"salary\",\"id\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85f4dbfb-1f72-4321-942e-ca01b47cffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Shiva| 60000|\n",
      "|  2| NULL| 45000|\n",
      "|  3|Reddy|     0|\n",
      "|  0|Kumar| 30000|\n",
      "|  5| NULL|     0|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill string  columns\n",
    "df2.fillna(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7903a9ae-5baf-48ec-9d31-4609f4e0b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1|Shiva| 60000|\n",
      "|  2| NULL| 45000|\n",
      "|  3|Reddy|     0|\n",
      "|  0|Kumar| 30000|\n",
      "|  5| NULL|     0|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.fillna(0, subset=[\"id\",\"salary\"]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "529ec1d2-8740-41f0-8f66-67e34c2b02c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+-------+\n",
      "|deptno| id|  name|salary|country|\n",
      "+------+---+------+------+-------+\n",
      "|    10|  1|  Ravi| 50000|  India|\n",
      "|    10|  2| Priya| 60000|  India|\n",
      "|    20|  3|  John| 45000|  India|\n",
      "|    20|  4|Rashmi| 80000|  India|\n",
      "|    30|  5|  Prem| 25000|  India|\n",
      "|    30|  6|Raheem| 50000|  India|\n",
      "|    10|  7| Sunil| 30000|  India|\n",
      "|    10|  8|  John| 35000|  India|\n",
      "|    20|  9| Susil| 45000|  India|\n",
      "|    10| 10| Jothi| 75000|  India|\n",
      "+------+---+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add constant column\n",
    "from pyspark.sql.functions import lit\n",
    "df.withColumn(\"country\", lit(\"India\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a878c51-8d04-4a86-9058-7d889518cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------+\n",
      "| id|         name|salary|\n",
      "+---+-------------+------+\n",
      "|  1|        Shiva| 60000|\n",
      "|  2|Not Available| 45000|\n",
      "|  3|        Reddy|     0|\n",
      "| -1|        Kumar| 30000|\n",
      "|  5|Not Available|     0|\n",
      "+---+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.fillna({\n",
    "    \"name\": \"Not Available\",\n",
    "    \"salary\": 0,\n",
    "    \"id\": -1\n",
    "}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fc41b42-4e14-4eee-99d7-5d8097544bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+---------------------+\n",
      "|deptno|id |name  |salary|Name_Country         |\n",
      "+------+---+------+------+---------------------+\n",
      "|10    |1  |Ravi  |50000 |Ravi belongs  India  |\n",
      "|10    |2  |Priya |60000 |Priya belongs  India |\n",
      "|20    |3  |John  |45000 |John belongs  India  |\n",
      "|20    |4  |Rashmi|80000 |Rashmi belongs  India|\n",
      "|30    |5  |Prem  |25000 |Prem belongs  India  |\n",
      "|30    |6  |Raheem|50000 |Raheem belongs  India|\n",
      "|10    |7  |Sunil |30000 |Sunil belongs  India |\n",
      "|10    |8  |John  |35000 |John belongs  India  |\n",
      "|20    |9  |Susil |45000 |Susil belongs  India |\n",
      "|10    |10 |Jothi |75000 |Jothi belongs  India |\n",
      "+------+---+------+------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit,concat\n",
    "df.withColumn(\"Name_Country\", concat(col(\"name\") , lit(\" belongs  India\")  )).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a016d3b8-5a10-441b-9a33-8fb0c9be48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+------+\n",
      "|deptno| id| name|salary|\n",
      "+------+---+-----+------+\n",
      "|    10|  1| Ravi| 50000|\n",
      "|    10|  2|Priya| 60000|\n",
      "+------+---+-----+------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c32e2e2d-1ae3-4996-83d5-3a2443415ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+----------------------+\n",
      "|deptno|id |name  |salary|ename_sal             |\n",
      "+------+---+------+------+----------------------+\n",
      "|10    |1  |Ravi  |50000 |Ravi Salary is 50000  |\n",
      "|10    |2  |Priya |60000 |Priya Salary is 60000 |\n",
      "|20    |3  |John  |45000 |John Salary is 45000  |\n",
      "|20    |4  |Rashmi|80000 |Rashmi Salary is 80000|\n",
      "|30    |5  |Prem  |25000 |Prem Salary is 25000  |\n",
      "|30    |6  |Raheem|50000 |Raheem Salary is 50000|\n",
      "|10    |7  |Sunil |30000 |Sunil Salary is 30000 |\n",
      "|10    |8  |John  |35000 |John Salary is 35000  |\n",
      "|20    |9  |Susil |45000 |Susil Salary is 45000 |\n",
      "|10    |10 |Jothi |75000 |Jothi Salary is 75000 |\n",
      "+------+---+------+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit, concat\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"ename_sal\",\n",
    "    concat(col(\"name\"),lit(\" Salary is \"), col(\"salary\").cast(\"string\"))\n",
    ")\n",
    "\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "371bc269-365b-4863-bb68-9b828e941533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+\n",
      "| id|  name|country|\n",
      "+---+------+-------+\n",
      "|  1|  Ravi|  India|\n",
      "|  2| Priya|  India|\n",
      "|  3|  John|  India|\n",
      "|  4|Rashmi|  India|\n",
      "|  5|  Prem|  India|\n",
      "|  6|Raheem|  India|\n",
      "|  7| Sunil|  India|\n",
      "|  8|  John|  India|\n",
      "|  9| Susil|  India|\n",
      "| 10| Jothi|  India|\n",
      "+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\",\"name\", lit(\"India\").alias(\"country\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "663d416d-360e-49e4-8a4b-b22c98157dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.salary > 50000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f904e60-2728-4c6b-8402-6cb2f67ef1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37f64a96-22ba-4f30-a843-cea718837557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+--------------------+\n",
      "|deptno| id|  name|salary|           ename_sal|\n",
      "+------+---+------+------+--------------------+\n",
      "|    10|  2| Priya| 60000|Priya Salary is 6...|\n",
      "|    20|  4|Rashmi| 80000|Rashmi Salary is ...|\n",
      "|    10| 10| Jothi| 75000|Jothi Salary is 7...|\n",
      "+------+---+------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"salary\") > 50000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64ff093f-9342-4940-82ec-c53953521989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"ename_sal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c8947e5-32fc-41ab-916c-d73bfdd4376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|salary|\n",
      "+---+------+\n",
      "|  1| 50000|\n",
      "|  2| 60000|\n",
      "|  7| 30000|\n",
      "|  8| 35000|\n",
      "| 10| 75000|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter( ( df.deptno ==10)  & (df.salary > 25000)  ).select(\"id\",\"salary\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f37c06c4-05be-48a4-a265-81621444b2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+------+\n",
      "|deptno| id| name|salary|\n",
      "+------+---+-----+------+\n",
      "|    10|  1| Ravi| 50000|\n",
      "|    10|  2|Priya| 60000|\n",
      "|    10| 10|Jothi| 75000|\n",
      "+------+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter using SQL-like string condition\n",
    "df.filter(\"salary > 40000 and deptno ==10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65ccba1f-7fa5-48e1-ae3b-0af4ac824d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"deptno\").isin(10,20)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1badec09-7c61-4203-9be1-c2acf509fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~col(\"deptno\").isin(10,20)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47c496be-7452-4c53-a04b-39cd08f30278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+------+\n",
      "|deptno| id|name|salary|\n",
      "+------+---+----+------+\n",
      "|    10|  1|Ravi| 50000|\n",
      "+------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"name\").like(\"Rav%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d5ac6cb-e950-49bf-bce2-cab7f7ec8217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter( ~col(\"name\").like(\"Rav%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0da94f2e-381d-4fe9-b619-b53328a24cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"name\").like(\"%em\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0579c702-3ecd-4c36-82b2-eb6386274dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+------+\n",
      "|deptno| id|name|salary|\n",
      "+------+---+----+------+\n",
      "+------+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"name\").like(\"%Kumar%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7e8a190-d08d-42dd-9167-84cd28e8f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  9| Susil| 45000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"salary\").between(20000, 50000)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59bccd28-9c1f-4e88-aa1f-47448000cdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~col(\"salary\").between(20000, 50000)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f10bce5-95f7-427d-920d-3550e798fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| id|  name|salary|\n",
      "+---+------+------+\n",
      "|  2| Priya| 60000|\n",
      "|  4|Rashmi| 80000|\n",
      "| 10| Jothi| 75000|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"id\",\"name\",\"salary\").filter(col(\"salary\") >50000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c3a33aa-1452-4351-ba6c-0e08af42c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1| Ravi| 50000|\n",
      "|  2| NULL| 60000|\n",
      "|  3| John|  NULL|\n",
      "|  4| NULL|  NULL|\n",
      "|  5|Priya| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, \"Ravi\", 50000),\n",
    "    (2, None, 60000),\n",
    "    (3, \"John\", None),\n",
    "    (4, None, None),\n",
    "    (5, \"Priya\", 45000)\n",
    "]\n",
    "\n",
    "df2 = spark.createDataFrame(data, [\"id\", \"name\", \"salary\"])\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70245c93-acef-4e86-bed9-679daaf8d1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+\n",
      "| id|name|salary|\n",
      "+---+----+------+\n",
      "|  3|John|  NULL|\n",
      "|  4|NULL|  NULL|\n",
      "+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(col(\"salary\").isNull()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3103197f-0f59-43b7-80af-4e56e0d6f2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id| name|salary|\n",
      "+---+-----+------+\n",
      "|  1| Ravi| 50000|\n",
      "|  3| John|  NULL|\n",
      "|  5|Priya| 45000|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(col(\"name\").isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cbe78d9-7e99-4528-a9e1-7d86d62f7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where( (col(\"salary\") >50000) | (col(\"deptno\") ==10)   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87d19b91-c716-4b95-b645-d4649a6bc66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"salary\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab944538-9b30-4271-9b6e-e69c64be174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(col(\"salary\").asc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9db2fbb7-5515-4e48-adfc-ae9337cb1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10| 10| Jothi| 75000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    30|  5|  Prem| 25000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\n",
    "    col(\"deptno\").asc(),\n",
    "    col(\"salary\").desc()\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76f028ea-67f0-48a5-8c6d-dae7d821815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.repartition(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "458d61a9-64d9-4740-a7ed-ba352bf860d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bc9f0390-9fb1-4f93-9381-50d4b1fdc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    30|  5|  Prem| 25000|\n",
      "|    10|  7| Sunil| 30000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  9| Susil| 45000|\n",
      "|    30|  6|Raheem| 50000|\n",
      "|    10| 10| Jothi| 75000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "|    10|  8|  John| 35000|\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "+------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sortWithinPartitions( \"salary\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a906986c-343e-4d1c-bcae-1059220254cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68b82a-a449-41b4-9f55-ee6732867c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f5bd114b-b22b-45e8-a0da-6b8e7f402462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+------+\n",
      "|deptno| id|  name|salary|\n",
      "+------+---+------+------+\n",
      "|    10|  1|  Ravi| 50000|\n",
      "|    10|  2| Priya| 60000|\n",
      "|    20|  3|  John| 45000|\n",
      "|    20|  4|Rashmi| 80000|\n",
      "+------+---+------+------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(4)%%!\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb681305-95fb-4511-a4c5-fc3fa3160cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deptno=20, id=3, name='John', salary=45000),\n",
       " Row(deptno=20, id=4, name='Rashmi', salary=80000),\n",
       " Row(deptno=30, id=5, name='Prem', salary=25000),\n",
       " Row(deptno=30, id=6, name='Raheem', salary=50000)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed289a41-c3f7-4e9d-b413-71d7366a61ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(deptno=10, id=10, name='Jothi', salary=75000),\n",
       " Row(deptno=10, id=1, name='Ravi', salary=50000),\n",
       " Row(deptno=10, id=2, name='Priya', salary=60000),\n",
       " Row(deptno=10, id=8, name='John', salary=35000)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cefc691b-e916-45ae-8609-19b8a00ad9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set operation\n",
    "df1 = spark.createDataFrame(\n",
    "    [(1, \"A\"), (2, \"B\"), (3, \"C\")],\n",
    "    [\"id\", \"val\"]\n",
    ")\n",
    "\n",
    "df2 = spark.createDataFrame(\n",
    "    [(3, \"C\"), (4, \"D\")],\n",
    "    [\"id\", \"val\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a62f4d0-1419-456e-88e0-87a209e40885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|val|\n",
      "+---+---+\n",
      "|  1|  A|\n",
      "|  2|  B|\n",
      "|  3|  C|\n",
      "|  3|  C|\n",
      "|  4|  D|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "59fc3a44-aaac-4222-a067-60e8c7986853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|val|\n",
      "+---+---+\n",
      "|  1|  A|\n",
      "|  2|  B|\n",
      "|  3|  C|\n",
      "|  3|  C|\n",
      "|  4|  D|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2c1a0833-d8cf-4721-a7a8-9a94e62333fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|val|\n",
      "+---+---+\n",
      "|  1|  A|\n",
      "|  2|  B|\n",
      "|  3|  C|\n",
      "|  4|  D|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dc9ff296-ce38-46ae-a193-cdaba645970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(data=(('a',1),('b',2)),schema=('col1 string,col2 int'))\n",
    "df4 = spark.createDataFrame(data=((2,'b'),(3,'c')),schema=('col2 int,col1 string'))\n",
    "df3.unionByName(df4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "09ef8fa1-2922-41ae-bece-b4ae8d947f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(data=(('a',1),('a',1),('b',2)),schema=('col1 string,col2 int')) \n",
    "df2 = spark.createDataFrame(data=(('a',1),('a',1),('c',2)),schema=('col1 string,col2 int'))\n",
    "df1.intersect(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f001590f-a137-406e-9dbd-dfdf5eb74295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   a|   1|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersectAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "adc846df-252c-4c8a-b84b-487d93925957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   b|   2|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.exceptAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "40deea86-52c0-41e0-9017-3fa6dc215e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+\n",
      "|emp_id| ename|dept_id|\n",
      "+------+------+-------+\n",
      "|     1| Smith|     10|\n",
      "|     2| Allen|     20|\n",
      "|     3|  Ward|     10|\n",
      "|     4| Jones|     30|\n",
      "|     5|Martin|   NULL|\n",
      "+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# EMP schema\n",
    "emp_schema = StructType([\n",
    "    StructField(\"emp_id\", IntegerType(), True),\n",
    "    StructField(\"ename\", StringType(), True),\n",
    "    StructField(\"dept_id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "emp_data = [\n",
    "    (1, \"Smith\", 10),\n",
    "    (2, \"Allen\", 20),\n",
    "    (3, \"Ward\", 10),\n",
    "    (4, \"Jones\", 30),\n",
    "    (5, \"Martin\", None)\n",
    "]\n",
    "\n",
    "emp = spark.createDataFrame(emp_data, emp_schema)\n",
    "\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "05a70a5b-195a-4da6-86c7-2d9d5e67aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|dept_id|     dname|\n",
      "+-------+----------+\n",
      "|     10|ACCOUNTING|\n",
      "|     20|  RESEARCH|\n",
      "|     30|     SALES|\n",
      "|     40|OPERATIONS|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEPT schema\n",
    "dept_schema = StructType([\n",
    "    StructField(\"dept_id\", IntegerType(), True),\n",
    "    StructField(\"dname\", StringType(), True)\n",
    "])\n",
    "\n",
    "dept_data = [\n",
    "    (10, \"ACCOUNTING\"),\n",
    "    (20, \"RESEARCH\"),\n",
    "    (30, \"SALES\"),\n",
    "    (40, \"OPERATIONS\")\n",
    "]\n",
    "\n",
    "dept = spark.createDataFrame(dept_data, dept_schema)\n",
    "dept.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "622cf2bd-3e10-4cff-a85d-ea38c96a1733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+----------+\n",
      "|emp_id|ename|deptid|     dname|\n",
      "+------+-----+------+----------+\n",
      "|     1|Smith|    10|ACCOUNTING|\n",
      "|     3| Ward|    10|ACCOUNTING|\n",
      "|     2|Allen|    20|  RESEARCH|\n",
      "|     4|Jones|    30|     SALES|\n",
      "+------+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emp.join(dept, emp.dept_id ==dept.deptid, how= \"inner\").\\\n",
    "    select(\"emp_id\",\"ename\",\"deptid\",\"dname\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ff11b5b9-7d3c-4eee-8915-0476685e56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|dept_id|emp_id| ename|     dname|\n",
      "+-------+------+------+----------+\n",
      "|     10|     1| Smith|ACCOUNTING|\n",
      "|     20|     2| Allen|  RESEARCH|\n",
      "|     10|     3|  Ward|ACCOUNTING|\n",
      "|     30|     4| Jones|     SALES|\n",
      "|   NULL|     5|Martin|      NULL|\n",
      "+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.join(dept, \"dept_id\", \"left\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4c449a8d-49e4-4ee0-862f-7341067b4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+----------+\n",
      "|dept_id|emp_id|ename|     dname|\n",
      "+-------+------+-----+----------+\n",
      "|     10|     3| Ward|ACCOUNTING|\n",
      "|     10|     1|Smith|ACCOUNTING|\n",
      "|     20|     2|Allen|  RESEARCH|\n",
      "|     30|     4|Jones|     SALES|\n",
      "|     40|  NULL| NULL|OPERATIONS|\n",
      "+-------+------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.join(dept, \"dept_id\", \"right\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e6f36870-d12f-4883-ba47-37507b0a3c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|dept_id|emp_id| ename|     dname|\n",
      "+-------+------+------+----------+\n",
      "|   NULL|     5|Martin|      NULL|\n",
      "|     10|     3|  Ward|ACCOUNTING|\n",
      "|     10|     1| Smith|ACCOUNTING|\n",
      "|     20|     2| Allen|  RESEARCH|\n",
      "|     30|     4| Jones|     SALES|\n",
      "|     40|  NULL|  NULL|OPERATIONS|\n",
      "+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.join(dept, \"dept_id\", \"full\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ab4f63de-279d-473d-83d1-9508d4dfda4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|dept_id|emp_id|ename|\n",
      "+-------+------+-----+\n",
      "|     10|     1|Smith|\n",
      "|     10|     3| Ward|\n",
      "|     20|     2|Allen|\n",
      "|     30|     4|Jones|\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Returns only employees whose dept exists.\n",
    "emp.join(dept, \"dept_id\", \"leftsemi\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "74a540a0-31c8-48fd-9d73-cd743ffb0996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|dept_id|emp_id| ename|\n",
      "+-------+------+------+\n",
      "|   NULL|     5|Martin|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Employees who do not have a matching department.\n",
    "emp.join(dept, \"dept_id\", \"leftanti\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "447942e1-1b88-4beb-bade-52fdbe933cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+-------+----------+\n",
      "|emp_id| ename|dept_id|dept_id|     dname|\n",
      "+------+------+-------+-------+----------+\n",
      "|     1| Smith|     10|     10|ACCOUNTING|\n",
      "|     1| Smith|     10|     20|  RESEARCH|\n",
      "|     1| Smith|     10|     30|     SALES|\n",
      "|     1| Smith|     10|     40|OPERATIONS|\n",
      "|     2| Allen|     20|     10|ACCOUNTING|\n",
      "|     2| Allen|     20|     20|  RESEARCH|\n",
      "|     2| Allen|     20|     30|     SALES|\n",
      "|     2| Allen|     20|     40|OPERATIONS|\n",
      "|     3|  Ward|     10|     10|ACCOUNTING|\n",
      "|     3|  Ward|     10|     20|  RESEARCH|\n",
      "|     3|  Ward|     10|     30|     SALES|\n",
      "|     3|  Ward|     10|     40|OPERATIONS|\n",
      "|     4| Jones|     30|     10|ACCOUNTING|\n",
      "|     4| Jones|     30|     20|  RESEARCH|\n",
      "|     4| Jones|     30|     30|     SALES|\n",
      "|     4| Jones|     30|     40|OPERATIONS|\n",
      "|     5|Martin|   NULL|     10|ACCOUNTING|\n",
      "|     5|Martin|   NULL|     20|  RESEARCH|\n",
      "|     5|Martin|   NULL|     30|     SALES|\n",
      "|     5|Martin|   NULL|     40|OPERATIONS|\n",
      "+------+------+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.crossJoin(dept).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
